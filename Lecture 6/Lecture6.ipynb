{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458424081e4aca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:20.436949889Z",
     "start_time": "2023-11-29T22:31:19.232336642Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3458424081e4aca0",
    "outputId": "267e59e6-0240-46cd-9618-b1d9b2a5de09"
   },
   "outputs": [],
   "source": [
    "!pip install qiskit-algorithms\n",
    "!pip install qiskit-machine-learning\n",
    "!pip install qiskit-Aer\n",
    "!pip install qiskit-qulacs\n",
    "!pip install matplotlib\n",
    "!pip install pylatexenc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa8b1fa",
   "metadata": {
    "id": "2fa8b1fa"
   },
   "source": [
    "# The Quantum Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1764d89",
   "metadata": {
    "id": "d1764d89"
   },
   "source": [
    "The goal of this tutorial is to build an Quantum Autoencoder, a circuit which can compress a quantum state onto a smaller amount of qubits, while retaining the information from the initial state.\n",
    "\n",
    "Throughout this tutorial, we explain the architecture of a Quantum Autoencoder and how one can design and train such a system to compress and encode information. Following this discussion, we give two examples to demonstrate the capabilities of such a system to compress different quantum states, as well as the ability to compress images of zeros and ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af97494",
   "metadata": {
    "id": "2af97494"
   },
   "source": [
    "## 1. What is an Autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246a6a6",
   "metadata": {
    "id": "9246a6a6"
   },
   "source": [
    "A classical autoencoder (CAE) is a type of neural network architecture that is commonly used to efficiently compress and encode information from the input using of representation learning. Following compression, one can then uncompress the data through the use of a decoder.\n",
    "\n",
    "Typical autoencoders are commonly divided into three layers, as seen in Figure 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f9027",
   "metadata": {
    "id": "9b1f9027"
   },
   "source": [
    "![qae_fig1_wide.png](https://github.com/osbama/Phys710/blob/master/Lecture%206/qae_fig1_wide.png?raw=1)\n",
    "Figure 1: Example of a Classical Autoencoder which includes the input, bottleneck and output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c4123a",
   "metadata": {
    "id": "d6c4123a"
   },
   "source": [
    "The first layer is called the Input Layer (1) and is the layer of which we input our data of length $n$.\n",
    "\n",
    "The input data then passes through an encoder and travels to the next layer, which has less nodes or is reduced in dimensions and is known as the Bottleneck Layer (2). The input layer is compressed through this process. Common CAEs may have several layers.\n",
    "\n",
    "The final layer is called the Output Layer (3). Here the compressed data is reconstructed to its original size, $n$, from the compressed data through the process of a decoder.\n",
    "\n",
    "By passing our input data through a CAE, we are therefore able to reduce the dimensionality of our input data, as seen in the bottleneck layer, while retaining as much information as possible from the input data. Because of this feature, common uses of CAE are Image Denoising, Anomaly Detection and Facial Recognition devices. For more information on classical autoencoders, see [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff37d8",
   "metadata": {
    "id": "a1ff37d8"
   },
   "source": [
    "## 2. The Quantum Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66031d83",
   "metadata": {
    "id": "66031d83"
   },
   "source": [
    "We can also define a quantum counterpart to the CAE, the Quantum Autoencoder. Much like the CAE, the Quantum Autoencoder aims to reduce the dimensionality of the input of the neural network, in this case a quantum state. A pictorial representation of this can be seen in Figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6a05e",
   "metadata": {
    "id": "31f6a05e"
   },
   "source": [
    "![qae_fig2_wide.png](https://github.com/osbama/Phys710/blob/master/Lecture%206/qae_fig2_wide.png?raw=1)\n",
    "Figure 2: Pictorial Representation of a Quantum Autoencoder. Here one can see the similarities with the CAE, with the circuit having an input state, bottleneck state and an output state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110c76f",
   "metadata": {
    "id": "1110c76f"
   },
   "source": [
    "\n",
    "\n",
    "Much like its classical counterpart, our circuit contains three layers. We first input our state $|\\psi>$ (which contains $n$ qubits), of which we wish to compress. This is our input layer (1).\n",
    "\n",
    "We then apply our parametrized circuit on our input state, which will act as our encoder and 'compresses' our quantum state, reducing the dimensionality of our state to $n-k$ qubits. Our new compressed state is of the form $|\\psi_{comp}> \\otimes |0>^{\\otimes k}$, where $|\\psi_{comp}>$ contains $n-k$ qubits.\n",
    "\n",
    "This parametrized circuit will depend on a set of parameters, which will be the nodes of our Quantum Autoencoder. Throughout the training process, these parameters will be updated to optimize the loss function.\n",
    "\n",
    "We disregard the remaining $k$ qubits for the remainder of the circuit. This is our bottleneck layer (2) and our input state is now compressed.\n",
    "\n",
    "The final layer consists of the addition of $k$ qubits (all in the state $|0\\rangle$) and applying another parametrized circuit between the compressed state and the new qubits. This parametrized circuit acts as our decoder and reconstructs the input state from the compressed state using the new qubits. After the decoder, we retain the original state as the state travels to the output layer (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ef78c0",
   "metadata": {
    "id": "38ef78c0"
   },
   "source": [
    "## 3. Components of a Quantum Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4aae55",
   "metadata": {
    "id": "1f4aae55"
   },
   "source": [
    "Before building our Quantum Autoencoder, we must note a few subtleties.\n",
    "\n",
    "We first note that we cannot introduce or disregard qubits in the middle of a Quantum Circuit when implementing an autoencoder using Qiskit.\n",
    "\n",
    "Because of this we must include our reference state as well as our auxiliary qubits (whose role will be described in later sections) at the beginning of the circuit.\n",
    "\n",
    "Therefore our input state will consist of our input state, reference state and one auxiliary qubit, as well as a classical register to perform measurements (which will be described in the next section). A pictorial representation of this can be seen in Figure 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-inspector",
   "metadata": {
    "id": "premium-inspector"
   },
   "source": [
    "![qae_fig3_wide.png](https://github.com/osbama/Phys710/blob/master/Lecture%206/qae_fig3_wide.png?raw=1)\n",
    "Figure 3: Pictorial Representation of input state of Quantum Autoencoder. Note that we must also include an auxiliary qubit, the reference state and classical register at the beginning of the circuit, even though they are not used until later in the circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faba1fc",
   "metadata": {
    "id": "5faba1fc"
   },
   "source": [
    "## 4. Choosing a Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6186d9a",
   "metadata": {
    "id": "b6186d9a"
   },
   "source": [
    "We now define our cost function, which we will use to train our Quantum Autoencoder, to return the input state. There's a bit of math involved here, so skip this section if you're not interested!\n",
    "\n",
    "We take the cost function as defined in [2], which tries to maximize the fidelity between the input and output state of our Quantum Autoencoder.\n",
    "\n",
    "We first define subsystems $A$ and $B$ to contain $n$ and $k$ qubits respectively, while $B'$ is the space which will contain our reference space. We call the subsystem $A$ our latent space, which will contain the compressed qubit state, and $B$ our trash space, which contain the qubits of which we disregard throughout compression.\n",
    "\n",
    "Our input state therefore $|\\psi_{AB}>$ contains $n + k$ qubits. We define the reference space $B'$ which contains the reference state $|a>_{B'}$. This space will contain the additional $k$ qubits we use in the decoder. All of these subsystems can be seen in Figure 3.\n",
    "\n",
    "We define the parameterized circuit as $U(\\theta)$ which we will use as our encoder. However the structure and parameters of our parametrized circuit is currently unknown to us and may vary for different input states. To determine the parameters to compress our input state, we must train our device to maximally compress the state by adjusting the values of the parameters $\\theta$. For the decoder we will use $U^{\\dagger}(\\theta)$.\n",
    "\n",
    "Our goal therefore is to maximize the fidelity between the input and output states, i.e.\n",
    "\n",
    "$$\\text{max }F(\\psi_{AB}, \\rho_{out})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\rho_{out} = U^{\\dagger}(\\theta)_{AB'} \\text{Tr}_{B} [U(\\theta)_{AB}[\\psi_{AB} \\otimes a_{B'}]U^{\\dagger}(\\theta)_{AB}]U(\\theta)_{AB'}$$\n",
    "\n",
    "We can maximize this fidelity by tuning the parameters $\\theta$ in our parametrized circuit. However, this fidelity can at times be complicated to determine and may require a large amount of gates needed to calculate the fidelity between two states, i.e. the larger the number of qubits, the more gates required which results to deeper circuits.  Therefore we look for alternative means of comparing the input and output states.\n",
    "\n",
    "As shown in [2] a simpler way of determining an optimally compressed state is to perform a swap gate between the trash state and reference state. These states usually have a smaller number of qubits and are therefore easier to compare, due to the smaller amount of gates required. As shown in [2] maximizing the fidelity of such these two states is equivalent to maximizing the fidelity of the input and output state and thus determining an optimal compression of our input circuit.\n",
    "\n",
    "Keeping our reference state fixed, our cost function will now be a function of the trash state and is denoted as;\n",
    "\n",
    "$$\\text{max }F(\\text{Tr}_{A} [ U(\\theta)_{AB}\\psi_{AB} U^{\\dagger}(\\theta)_{AB}], a_{B'})$$\n",
    "\n",
    "Throughout the training process, we adjust the parameters $\\theta$ in our encoder and perform a swap test (as described below) to determine the fidelity between these trash and reference states. In doing so, we must include an additional qubit, our auxiliary qubit, which will be used throughout the swap test and measured to determine the overall fidelity of the trash and reference states. This is the reason why we included both an auxiliary qubit and classical register in the previous section when initializing our circuit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f5611",
   "metadata": {
    "id": "af4f5611"
   },
   "source": [
    "### The SWAP Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721636a1",
   "metadata": {
    "id": "721636a1"
   },
   "source": [
    "The SWAP Test is a procedure commonly used to compare two states by applying CNOT gates to each qubit (for further information see [3]). By running the circuit $M$ times, and applying the SWAP test, we then measure the auxiliary qubit. We use the number of states in the state $|1\\rangle$ to compute:\n",
    "\n",
    "$$S = 1 - \\frac{2}{M}L$$\n",
    "\n",
    "where $L$ is the count for the states in the $|1\\rangle$ state. As shown in [3], maximizing this function corresponds to the two states of which we are comparing being identical. We therefore aim to maximize this function, i.e. minimize  $\\frac{2}{M}L$. This value will be therefore be our cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24563883",
   "metadata": {
    "id": "24563883"
   },
   "source": [
    "## 5. Building the Quantum Autoencoder Ansatz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17e37a",
   "metadata": {
    "id": "aa17e37a"
   },
   "source": [
    "First, we implement IBM's Qiskit to build our Quantum Autoencoder. We first begin by importing in the necessary libraries and fixing the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497cb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:21.550452282Z",
     "start_time": "2023-11-29T22:31:19.724223723Z"
    },
    "id": "6497cb31"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import math\n",
    "import qiskit\n",
    "from qiskit.visualization import plot_histogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from qiskit import ClassicalRegister, QuantumRegister\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793bc10",
   "metadata": {
    "id": "5793bc10"
   },
   "source": [
    "We begin by defining our parametrized ansatz for the Quantum Autoencoder. This will be our parametrized circuit where we can tune the parameters to maximize the fidelity between the trash and reference states.\n",
    "\n",
    "### The Parametrized Circuit\n",
    "\n",
    "The parametrized circuit we will use below for our encoder is the RealAmplitude Ansatz available in Qiskit. One of the reasons why we have chosen this ansatz is because it is a 2-local circuit, the prepared quantum states will only have real amplitudes, and does not rely on full connectivity between each qubits, which is hard to implement or can lead to deep circuits.\n",
    "\n",
    "We define our parametrized circuit for our Encoder below, where we set the repetition parameter to `reps=5`, to increase the number of parameters in our circuit allowing greater flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78152563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:21.553236237Z",
     "start_time": "2023-11-29T22:31:21.551021364Z"
    },
    "id": "78152563"
   },
   "outputs": [],
   "source": [
    "def ansatz(num_qubits):\n",
    "    return RealAmplitudes(num_qubits, reps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-atmosphere",
   "metadata": {
    "id": "seasonal-atmosphere"
   },
   "source": [
    "Let's draw this ansatz with $5$ qubits and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-consensus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.266836396Z",
     "start_time": "2023-11-29T22:31:21.554723281Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "expanded-consensus",
    "outputId": "bf2ea482-64c1-4156-b595-64bceffa2125"
   },
   "outputs": [],
   "source": [
    "num_qubits = 5\n",
    "circ = ansatz(num_qubits)\n",
    "circ.decompose().draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8925b02",
   "metadata": {
    "id": "c8925b02"
   },
   "source": [
    "We now apply this Encoder to the state we wish to compress. In this example, we divide our initial $5$ qubit state into a $3$ qubit latent state ($n = 3$) and $2$ qubit trash space ($k = 2$).\n",
    "\n",
    "As explained in the previous section, we must also include a $2$ qubit reference space in our circuit, as well as an auxiliary qubit to perform the swap test between the reference and trash states. We will therefore have a total of $2 + 3 + 2 + 1 = 8$ qubits and $1$ classical register in our circuit.\n",
    "\n",
    "After initializing our state, we apply our parametrized circuit.\n",
    "\n",
    "Following this, we then split our initial state into the latent space (the compressed state) and trash space (the part of the state we will disregard) and perform the swap test between the reference state and the trash space. The last qubit is then measured to determine the fidelity between the reference and trash states.  A pictorial representation of this is given below in Figure 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-blond",
   "metadata": {
    "id": "bound-blond"
   },
   "source": [
    "![qae_fig4_wide.png](https://github.com/osbama/Phys710/blob/master/Lecture%206/qae_fig4_wide.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edf744",
   "metadata": {
    "id": "31edf744"
   },
   "source": [
    "Figure 4: Example of a Quantum Autoencoder in the training process. We use the swap test to determine the fidelity between the trash and reference space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d20fb",
   "metadata": {
    "id": "d24d20fb"
   },
   "source": [
    "We define a function below to implement the above circuit configuration to the $5$ qubit domain wall state $|00111\\rangle$ and plot an example below. Here qubits $5$ and $6$ are the reference state, $0, 1, 2, 3, 4$ are the initial state we wish to compress and qubit $7$ is our auxiliary qubit which is used in the swap test. We also include a classical register to measure the results of qubit $7$ in the swap test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d415550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.431618631Z",
     "start_time": "2023-11-29T22:31:22.273940108Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "1d415550",
    "outputId": "ba313130-899f-48ba-8113-de77a3f3295e"
   },
   "outputs": [],
   "source": [
    "def auto_encoder_circuit(num_latent, num_trash):\n",
    "    qr = QuantumRegister(num_latent + 2 * num_trash + 1, \"q\")\n",
    "    cr = ClassicalRegister(1, \"c\")\n",
    "    circuit = QuantumCircuit(qr, cr)\n",
    "    circuit.compose(ansatz(num_latent + num_trash), range(0, num_latent + num_trash), inplace=True)\n",
    "    circuit.barrier()\n",
    "    auxiliary_qubit = num_latent + 2 * num_trash\n",
    "    # swap test\n",
    "    circuit.h(auxiliary_qubit)\n",
    "    for i in range(num_trash):\n",
    "        circuit.cswap(auxiliary_qubit, num_latent + i, num_latent + num_trash + i)\n",
    "\n",
    "    circuit.h(auxiliary_qubit)\n",
    "    circuit.measure(auxiliary_qubit, cr[0])\n",
    "    return circuit\n",
    "\n",
    "\n",
    "num_latent = 3\n",
    "num_trash = 2\n",
    "circuit = auto_encoder_circuit(num_latent, num_trash)\n",
    "circuit.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0bc911",
   "metadata": {
    "id": "2c0bc911"
   },
   "source": [
    "In order to reconstruct the original input state, we must apply the adjoint of our parametrized circuit after the swap test. However, during training, we are only interested in the trash state and the reference state. We can therefore exclude the gates following compression until we wish to reconstruct our initial input.\n",
    "\n",
    "After building our Quantum Autoencoder, the next step is to train our Quantum Autoencoder to compress the state and maximize the cost function and determine the parameters $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a578973",
   "metadata": {
    "id": "7a578973"
   },
   "source": [
    "## 6. A Simple Example: The Domain Wall Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc886404",
   "metadata": {
    "id": "bc886404"
   },
   "source": [
    "Let's first begin with a simple example, a state known as the Domain Wall, which for $5$ qubits is given by $|00111\\rangle$. Here we will try and compress this state from $5$ qubits to $3$ qubits, with the remaining qubits in the trash space, in the state $|00\\rangle$. We can create a function to build the domain wall state below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787d73c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.512442111Z",
     "start_time": "2023-11-29T22:31:22.431840594Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "2787d73c",
    "outputId": "bf2c947c-c421-4f2d-8590-5f7a1d01f2e6"
   },
   "outputs": [],
   "source": [
    "def domain_wall(circuit, a, b):\n",
    "    # Here we place the Domain Wall to qubits a - b in our circuit\n",
    "    for i in np.arange(int(b / 2), int(b)):\n",
    "        circuit.x(i)\n",
    "    return circuit\n",
    "\n",
    "\n",
    "domain_wall_circuit = domain_wall(QuantumCircuit(5), 0, 5)\n",
    "domain_wall_circuit.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc66776",
   "metadata": {
    "id": "dcc66776"
   },
   "source": [
    "Now let's train our Autoencoder to compress this state from 5 qubits to 3 qubits (qubits 0,1 and 2), with the remaining qubits in the trash space (qubits 3 and 4) being in the |00> state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8442b1",
   "metadata": {
    "id": "4a8442b1"
   },
   "source": [
    "We create a circuit to be used in the loss function, as described in Section 4, which determines the fidelity between the two states below using the swap test for our particular AutoEncoder function. For further information on the swap test, see [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602efbb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.650720869Z",
     "start_time": "2023-11-29T22:31:22.510614757Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "602efbb0",
    "outputId": "92836302-4ef1-47d6-cf50-e987eb51d8cb"
   },
   "outputs": [],
   "source": [
    "ae = auto_encoder_circuit(num_latent, num_trash)\n",
    "qc = QuantumCircuit(num_latent + 2 * num_trash + 1, 1)\n",
    "qc = qc.compose(domain_wall_circuit, range(num_latent + num_trash))\n",
    "qc = qc.compose(ae)\n",
    "qc.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-distributor",
   "metadata": {
    "id": "reasonable-distributor"
   },
   "source": [
    "Then, we create a quantum neural network and pass the circuit as a parameter. We note that this network must take an interpret function, which determines how we map the output of the network to the output shape. Since we measure only one qubit, the output of the network is a bit string either $0$ or $1$, so the output shape is $2$, the number of possible outcomes. Then, we introduce an identity mapping. The output of the network is a vector of probabilities of getting interpret-mapped bit strings. Thus, we get probabilities of getting $0$ or $1$ and this is exactly what we are looking for. In the cost function we make use of the probability of getting $1$ and penalize the outcomes that lead to $1$, therefore maximizing the fidelity between the trash space and the reference space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-township",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.776102293Z",
     "start_time": "2023-11-29T22:31:22.654554842Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "varying-township",
    "outputId": "82add177-9659-4e68-dd0b-3a06c020a0ba"
   },
   "outputs": [],
   "source": [
    "# Here we define our interpret for our SamplerQNN\n",
    "def identity_interpret(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "qnn = SamplerQNN(\n",
    "    circuit=qc,\n",
    "    input_params=[],\n",
    "    weight_params=ae.parameters,\n",
    "    interpret=identity_interpret,\n",
    "    output_shape=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0fea32",
   "metadata": {
    "id": "fa0fea32"
   },
   "source": [
    "Next we create our cost function. As described in the previous section, our aim is to minimize $\\frac{2}{M}L$, which is the twice the probability of getting the final qubit in the $|1\\rangle$ state. We therefore wish to minimize the of getting a $|1\\rangle$ on qubit 7.\n",
    "\n",
    "The cost function will also plot out the objective value at each cost function evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abf03b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:22.776416694Z",
     "start_time": "2023-11-29T22:31:22.696218834Z"
    },
    "id": "28abf03b"
   },
   "outputs": [],
   "source": [
    "def cost_func_domain(params_values):\n",
    "    probabilities = qnn.forward([], params_values)\n",
    "    # we pick a probability of getting 1 as the output of the network\n",
    "    cost = np.sum(probabilities[:, 1])\n",
    "\n",
    "    # plotting part\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(cost)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97545c2",
   "metadata": {
    "id": "c97545c2"
   },
   "source": [
    "Now we will train our Autoencoder to reduce the dimension of the Hilbert space from $5$ qubits to $3$, while leaving the trash space in the state $|00\\rangle$.  We initially set the parameters $\\theta$ to random values and tune these parameters to minimize our cost function through the use of the COBYLA optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71344086",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "71344086",
    "outputId": "156f615e-3a3d-4c37-d09d-943f0d527d8f"
   },
   "outputs": [],
   "source": [
    "opt = COBYLA(maxiter=150)\n",
    "initial_point = algorithm_globals.random.random(ae.num_parameters)\n",
    "\n",
    "objective_func_vals = []\n",
    "# make the plot nicer\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "start = time.time()\n",
    "opt_result = opt.minimize(cost_func_domain, initial_point)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"Fit in {elapsed:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242ad6d",
   "metadata": {
    "id": "0242ad6d"
   },
   "source": [
    "Looks like it has converged! After training our Quantum Autoencoder, let's build it and see how well it compresses the state!\n",
    "\n",
    "To do this, we first apply our Autoencoder to a $5$ qubit Domain Wall state. After applying this state, the compressed state should be of the form $|00\\rangle$. Therefore resetting the last two qubits should not effect our over all state.\n",
    "\n",
    "After resetting we apply our decoder (the hermitian conjugate of our encoder) and compare it to the initial state by determining the fidelity. If our fidelity is one, then our Autoencoder has encoded all the information of the domain wall efficiently into a smaller set of qubits and when decoding, we retain the original state!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88b086",
   "metadata": {
    "id": "4c88b086"
   },
   "source": [
    "Let's first apply our circuit to the Domain Wall State, using the parameters we obtained when training our Quantum Autoencoder. (Note we have included barriers in our circuit below, however these are not necessary for the implementation of the Quantum Autoencoder and are used to determine between different sections of our circuit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749338a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.422412731Z",
     "start_time": "2023-11-29T22:31:42.128870925Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "749338a0",
    "outputId": "d577fb1f-5d26-4768-c887-0397bd5118bb"
   },
   "outputs": [],
   "source": [
    "test_qc = QuantumCircuit(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(domain_wall_circuit)\n",
    "ansatz_qc = ansatz(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(ansatz_qc)\n",
    "test_qc.barrier()\n",
    "test_qc.reset(4)\n",
    "test_qc.reset(3)\n",
    "test_qc.barrier()\n",
    "test_qc = test_qc.compose(ansatz_qc.inverse())\n",
    "\n",
    "test_qc.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-canal",
   "metadata": {
    "id": "grand-canal"
   },
   "source": [
    "Now we assign the parameter values obtained in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-marina",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.446485213Z",
     "start_time": "2023-11-29T22:31:42.429351149Z"
    },
    "id": "shaped-marina"
   },
   "outputs": [],
   "source": [
    "test_qc = test_qc.assign_parameters(opt_result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce4200",
   "metadata": {
    "id": "8dce4200"
   },
   "source": [
    "Now let's get the statevectors of our Domain Wall state and output circuit and calculate the fidelity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756cfa05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.446826452Z",
     "start_time": "2023-11-29T22:31:42.431458554Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "756cfa05",
    "outputId": "8a78ba0a-c93d-4a22-c9af-86b33d8a52b0"
   },
   "outputs": [],
   "source": [
    "domain_wall_state = Statevector(domain_wall_circuit).data\n",
    "output_state = Statevector(test_qc).data\n",
    "\n",
    "fidelity = np.sqrt(np.dot(domain_wall_state.conj(), output_state) ** 2)\n",
    "print(\"Fidelity of our Output State with our Input State: \", fidelity.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618128d3",
   "metadata": {
    "id": "618128d3"
   },
   "source": [
    "As you can see our fidelity is quite high and our Autoencoder has thus compressed our dataset while retaining all the information from the input state!\n",
    "\n",
    "Now we will see if we can apply such a Quantum Autoencoder to more complicated datasets containing noise, such as images of the numbers zero and one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5be665",
   "metadata": {
    "id": "0b5be665"
   },
   "source": [
    "## 7. A Quantum Autoencoder for Digital Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f37a6",
   "metadata": {
    "id": "4f6f37a6"
   },
   "source": [
    "One can also apply a Quantum Autoencoder to more complicated examples, such as a set of handwritten digits in order to compress the dataset. Below, we will show that we can indeed train an Quantum Autoencoder to compress such an example, giving us the ability to store data more efficiently on a Quantum Computer.\n",
    "\n",
    "For this tutorial, we will build a Quantum Autoencoder for a noisy dataset containing zeros and ones, which can be seen below.\n",
    "\n",
    "Each image contains $32$ pixels of which can be encoded into $5$ qubits by Amplitude Encoding. This can be done using Qiskit Machine Learning's `RawFeatureVector` feature map.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d40622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.609227670Z",
     "start_time": "2023-11-29T22:31:42.446245860Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "41d40622",
    "outputId": "137d828c-3e9f-4a59-e9a5-eddccf22d2d5"
   },
   "outputs": [],
   "source": [
    "def zero_idx(j, i):\n",
    "    # Index for zero pixels\n",
    "    return [\n",
    "        [i, j],\n",
    "        [i - 1, j - 1],\n",
    "        [i - 1, j + 1],\n",
    "        [i - 2, j - 1],\n",
    "        [i - 2, j + 1],\n",
    "        [i - 3, j - 1],\n",
    "        [i - 3, j + 1],\n",
    "        [i - 4, j - 1],\n",
    "        [i - 4, j + 1],\n",
    "        [i - 5, j],\n",
    "    ]\n",
    "\n",
    "\n",
    "def one_idx(i, j):\n",
    "    # Index for one pixels\n",
    "    return [[i, j - 1], [i, j - 2], [i, j - 3], [i, j - 4], [i, j - 5], [i - 1, j - 4], [i, j]]\n",
    "\n",
    "\n",
    "def get_dataset_digits(num, draw=True):\n",
    "    # Create Dataset containing zero and one\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for i in range(int(num / 2)):\n",
    "        # First we introduce background noise\n",
    "        empty = np.array([algorithm_globals.random.uniform(0, 0.1) for i in range(32)]).reshape(\n",
    "            8, 4\n",
    "        )\n",
    "\n",
    "        # Now we insert the pixels for the one\n",
    "        for i, j in one_idx(2, 6):\n",
    "            empty[j][i] = algorithm_globals.random.uniform(0.9, 1)\n",
    "        train_images.append(empty)\n",
    "        train_labels.append(1)\n",
    "        if draw:\n",
    "            plt.title(\"This is a One\")\n",
    "            plt.imshow(train_images[-1])\n",
    "            plt.show()\n",
    "\n",
    "    for i in range(int(num / 2)):\n",
    "        empty = np.array([algorithm_globals.random.uniform(0, 0.1) for i in range(32)]).reshape(\n",
    "            8, 4\n",
    "        )\n",
    "\n",
    "        # Now we insert the pixels for the zero\n",
    "        for k, j in zero_idx(2, 6):\n",
    "            empty[k][j] = algorithm_globals.random.uniform(0.9, 1)\n",
    "\n",
    "        train_images.append(empty)\n",
    "        train_labels.append(0)\n",
    "        if draw:\n",
    "            plt.imshow(train_images[-1])\n",
    "            plt.title(\"This is a Zero\")\n",
    "            plt.show()\n",
    "\n",
    "    train_images = np.array(train_images)\n",
    "    train_images = train_images.reshape(len(train_images), 32)\n",
    "\n",
    "    for i in range(len(train_images)):\n",
    "        sum_sq = np.sum(train_images[i] ** 2)\n",
    "        train_images[i] = train_images[i] / np.sqrt(sum_sq)\n",
    "\n",
    "    return train_images, train_labels\n",
    "\n",
    "\n",
    "train_images, __ = get_dataset_digits(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f12b6",
   "metadata": {
    "id": "646f12b6"
   },
   "source": [
    "After encoding our image into $5$ qubits, we begin to train our Quantum Autoencoder to compress this state into $3$ qubits.\n",
    "\n",
    "We repeat the steps in the previous example and write a cost function, again based on the Swap Test between the trash and latent space. We can also use the same Autoencoder function as given in the previous example, as the input state and trash space contain the same amount of qubits.\n",
    "\n",
    "Let's input one of our digits and see our circuit for the Autoencoder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ec8f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.921266479Z",
     "start_time": "2023-11-29T22:31:42.619631100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "id": "a11ec8f3",
    "outputId": "88bd0059-c20e-4fae-b018-7a1240832090"
   },
   "outputs": [],
   "source": [
    "num_latent = 3\n",
    "num_trash = 2\n",
    "\n",
    "fm = RawFeatureVector(2 ** (num_latent + num_trash))\n",
    "\n",
    "ae = auto_encoder_circuit(num_latent, num_trash)\n",
    "\n",
    "qc = QuantumCircuit(num_latent + 2 * num_trash + 1, 1)\n",
    "qc = qc.compose(fm, range(num_latent + num_trash))\n",
    "qc = qc.compose(ae)\n",
    "\n",
    "qc.draw(\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd4db6",
   "metadata": {
    "id": "effd4db6"
   },
   "source": [
    "Again, we can see the swap test being performed on the qubits $3$, $4$, $5$ and $6$, which will determine the value of our cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b80ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.921806992Z",
     "start_time": "2023-11-29T22:31:42.808162947Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "301b80ad",
    "outputId": "8ed1c647-d65a-412e-e1ed-6ee53b2652d9"
   },
   "outputs": [],
   "source": [
    "def identity_interpret(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "qnn = SamplerQNN(\n",
    "    circuit=qc,\n",
    "    input_params=fm.parameters,\n",
    "    weight_params=ae.parameters,\n",
    "    interpret=identity_interpret,\n",
    "    output_shape=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-second",
   "metadata": {
    "id": "inner-second"
   },
   "source": [
    "We build our cost function, based on the swap test between the reference and trash space for the digit dataset. To do this, we again use Qiskit Machine Learning's SamplerQNN network and use the same interpret function as we are measuring the probability of getting the final qubit in the $|1\\rangle$ state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-negotiation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.921946238Z",
     "start_time": "2023-11-29T22:31:42.808352131Z"
    },
    "id": "frequent-negotiation"
   },
   "outputs": [],
   "source": [
    "def cost_func_digits(params_values):\n",
    "    probabilities = qnn.forward(train_images, params_values)\n",
    "    cost = np.sum(probabilities[:, 1]) / train_images.shape[0]\n",
    "\n",
    "    # plotting part\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(cost)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868874b",
   "metadata": {
    "id": "d868874b"
   },
   "source": [
    "Since model training may take a long time we have already pre-trained the model for some iterations and saved the pre-trained weights. We'll continue training from that point by setting `initial_point` to a vector of pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34af70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:31:42.922049295Z",
     "start_time": "2023-11-29T22:31:42.808417859Z"
    },
    "id": "cd34af70"
   },
   "outputs": [],
   "source": [
    "with open(\"qae_initial_point.json\", \"r\") as f:\n",
    "    initial_point = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99a0c03",
   "metadata": {
    "id": "a99a0c03"
   },
   "source": [
    "By minimizing this cost function, we can thus determine the required parameters to compress our noisy images. Let's see if we can encode our images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4b67e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "a2e4b67e",
    "outputId": "38edbe89-ff3a-4c5b-8e90-a62e5db98d51"
   },
   "outputs": [],
   "source": [
    "opt = COBYLA(maxiter=150)\n",
    "\n",
    "objective_func_vals = []\n",
    "# make the plot nicer\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "start = time.time()\n",
    "opt_result = opt.minimize(fun=cost_func_digits, x0=initial_point)\n",
    "elapsed = time.time() - start\n",
    "print(f\"Fit in {elapsed:0.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c92af0a",
   "metadata": {
    "id": "0c92af0a"
   },
   "source": [
    "Looks like it has converged!\n",
    "\n",
    "Now let's build our Encoder and Decoder using the parameters obtained from the training period. After applying this circuit to our new dataset, we can then compare our input and output data and see if we were able to retain the images efficiently throughout the compression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d847b99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:01.868984300Z",
     "start_time": "2023-11-29T22:32:01.452828625Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8d847b99",
    "outputId": "a901cb78-b083-4012-e024-7a544056ce67",
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test_qc = QuantumCircuit(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(fm)\n",
    "ansatz_qc = ansatz(num_latent + num_trash)\n",
    "test_qc = test_qc.compose(ansatz_qc)\n",
    "test_qc.barrier()\n",
    "test_qc.reset(4)\n",
    "test_qc.reset(3)\n",
    "test_qc.barrier()\n",
    "test_qc = test_qc.compose(ansatz_qc.inverse())\n",
    "\n",
    "# sample new images\n",
    "test_images, test_labels = get_dataset_digits(2, draw=False)\n",
    "for image, label in zip(test_images, test_labels):\n",
    "    original_qc = fm.assign_parameters(image)\n",
    "    original_sv = Statevector(original_qc).data\n",
    "    original_sv = np.reshape(np.abs(original_sv) ** 2, (8, 4))\n",
    "\n",
    "    param_values = np.concatenate((image, opt_result.x))\n",
    "    output_qc = test_qc.assign_parameters(param_values)\n",
    "    output_sv = Statevector(output_qc).data\n",
    "    output_sv = np.reshape(np.abs(output_sv) ** 2, (8, 4))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.imshow(original_sv)\n",
    "    ax1.set_title(\"Input Data\")\n",
    "    ax2.imshow(output_sv)\n",
    "    ax2.set_title(\"Output Data\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecfe78e",
   "metadata": {
    "id": "8ecfe78e"
   },
   "source": [
    "It looks like our Quantum Autoencoder can be trained to encode digits as well! Now it's your turn to build your own Quantum Autoencoder and come up with ideas and datasets to compress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae71d1a3",
   "metadata": {
    "id": "ae71d1a3"
   },
   "source": [
    "## 8. Applications of a Quantum Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c076968",
   "metadata": {
    "id": "9c076968"
   },
   "source": [
    "Quantum Autoencoder's can be used for various different applications, including\n",
    "\n",
    "1. Digital Compression: where information can be encoded into a smaller amount of qubits. This can be hugely beneficial for near term quantum devices, as smaller systems of qubits are less prone to noise.\n",
    "2. Denoising: where one can use Quantum Autoencoder to extract relevant features from the initial quantum state or encoded data, while neglecting any additional noise.\n",
    "3. Quantum Chemistry: in which a Quantum Autoencoder can be used as an ansatz for systems, such as the Hubbard Model. This is commonly used to describe electron-electron interactions in molecules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe10aca",
   "metadata": {
    "id": "fbe10aca"
   },
   "source": [
    "# 9. Learning hard distributions with quantum-enhanced Variational Autoencoders\n",
    "\n",
    "In a recent application \\[4\\], a  quantum-enhanced VAE (QeVAE), was applied to the problem of modeling the measurement distributions obtained from unknown quantum states. This problem is fundamental in quantum information science, as it can reveal useful information about the properties and dynamics of quantum systems. Moreover, it can enable applications such as quantum state reconstruction, and entanglement quantiﬁcation.\n",
    "\n",
    "The hybrid model consists of a feed-forward classical encoder, a continuous latent space, and a parametrized quantum circuit as a decoder. The encoder network Qφ(z|x) is modelled through a classical feedforward neural network and the latent variable as z ∼ N (0, I). The likelihood (generator) distribution pθ (x|z) is defined via a quantum circuit i.e. pθ (x|z) =| 〈x| ˆU (θ, z)|0〉⊗n〉 |2. The Evidence Lower bound loss (ELBO) is optimized through a classical optimizer such as ADAM. The model is trained to mimic the given measurement distribution of states. During training, the parameters of the encoder and the rotation gates in the decoder (with a pre-selected entanglement type) are iteratively varied and learned. Such a model has multiple applications: It will enable scientists to generate certain quantum states in different physical quantum computers just by knowing the set of rotation and entangling gates to perform. The algorithm also has applications in state compression and transferring a state from one system to another upto a phase.\n",
    "\n",
    "![](https://github.com/osbama/Phys710/blob/master/Lecture%206/QVAE.png?raw=1)\n",
    "\n",
    "QeVAE for learning quantum state distributions: (a) Multiple copies of a quantum state ρ are obtained naturally from a quantum system and are measured through different measurement operators. The measurement dataset is stored on a classical computer. (b) The QeVAE with a parameterized quantum circuit as the generative network and a classical feed-forward neural network as the inference network can be used to recrete the distribution. After training, the circuit can be used to generate the original distribution through any quantum computer and generate states amenable for downstream processing. (c) A classical VAE with continuous Gaussian latent variables that perform the same task.\n",
    "\n",
    "## Generate random quantum circuit states\n",
    "\n",
    "- Through arbitrary rotations and entangling gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382ae29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:01.923894645Z",
     "start_time": "2023-11-29T22:32:01.869787735Z"
    },
    "id": "c382ae29"
   },
   "outputs": [],
   "source": [
    "def normalize(d, target=1.0):\n",
    "   raw = sum(d.values())\n",
    "   factor = target/raw\n",
    "   return {key:value*factor for key,value in d.items()}\n",
    "\n",
    "def conv_resultdict_nparray(results:dict, nqubits:int) -> np.ndarray:\n",
    "    \"\"\"Convert quantum circuit results (dict) into a 2D matrix\n",
    "    that stores all the binary vectors.\n",
    "    First we get all the strings obtained for each measurement (m) and then convert each bitstring into\n",
    "    a n-column vector. Such a vector is created for each measurement, yielding a 2D matrix (m, n)\"\"\"\n",
    "\n",
    "    result_array_str = np.concatenate([[key]*results[key] for key in results])\n",
    "    result_array_vec = np.zeros((result_array_str.shape[0], nqubits))\n",
    "    for rowid, row in enumerate(result_array_str):\n",
    "        for colid, elem in enumerate(row):\n",
    "            if elem.isspace()==True : break\n",
    "            result_array_vec[rowid-1, colid-1] = int(elem)\n",
    "\n",
    "    print(\"Result loaded on numpy array! Output shape:\",(result_array_vec.shape))\n",
    "    return np.random.permutation(result_array_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fe877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:01.924037930Z",
     "start_time": "2023-11-29T22:32:01.912054499Z"
    },
    "id": "157fe877"
   },
   "outputs": [],
   "source": [
    "nqubits = 4\n",
    "seed = algorithm_globals.random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6be56b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.284702501Z",
     "start_time": "2023-11-29T22:32:01.912139776Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6a6be56b",
    "outputId": "8ce2690f-570c-40f4-9e0b-e2d27109364d"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "circ_simple = qiskit.QuantumCircuit(nqubits)\n",
    "circ_simple.h(range(nqubits))\n",
    "circ_simple.x(range(nqubits//2)); circ_simple.y(range(nqubits//2, nqubits)); circ_simple.barrier()\n",
    "for i in range(20):\n",
    "    circ_simple.cx(range(nqubits-1), range(1,nqubits)); circ_simple.barrier()\n",
    "    [circ_simple.rx(2*np.pi*(2*np.random.rand(1)[0]-1), i) for i in range(nqubits)]\n",
    "    [circ_simple.ry(2*np.pi*(2*np.random.rand(1)[0]-1), i) for i in range(nqubits)] ; circ_simple.barrier()\n",
    "circ_simple.cx(range(nqubits-1), range(1,nqubits)); circ_simple.barrier()\n",
    "circ_simple.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef497a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.286639631Z",
     "start_time": "2023-11-29T22:32:03.284277904Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ef497a9",
    "outputId": "73e2b100-82c3-4a8a-f1ea-266fd7e57a94"
   },
   "outputs": [],
   "source": [
    "circ_simple.count_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006a8b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.610051250Z",
     "start_time": "2023-11-29T22:32:03.284483368Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 754
    },
    "id": "e006a8b2",
    "outputId": "20c57ba9-f181-4715-cb71-150642a64daf"
   },
   "outputs": [],
   "source": [
    "circ_simple.measure_all()\n",
    "from qiskit_aer import Aer\n",
    "job = Aer.get_backend('qasm_simulator').run(circ_simple, shots=pow(2,13))\n",
    "results = job.result().get_counts()\n",
    "plot_histogram(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43913da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.610745718Z",
     "start_time": "2023-11-29T22:32:03.510867362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c43913da",
    "outputId": "00277784-febb-4829-d013-5833b02dc2e6"
   },
   "outputs": [],
   "source": [
    "outputfile = conv_resultdict_nparray(results, nqubits) #np.random.permutation(result_array_vec)\n",
    "outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49748b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.610941052Z",
     "start_time": "2023-11-29T22:32:03.521398029Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49748b66",
    "outputId": "ea8608fe-23e6-47a5-8397-549acf87e64a"
   },
   "outputs": [],
   "source": [
    "n_samples = outputfile.shape[0]\n",
    "n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c439fe",
   "metadata": {
    "id": "50c439fe"
   },
   "source": [
    "## Creating a QeVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e8000",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611130046Z",
     "start_time": "2023-11-29T22:32:03.526288960Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4e2e8000",
    "outputId": "f064a698-fbc5-4870-a958-5fa1abed4f77"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462a55f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611318820Z",
     "start_time": "2023-11-29T22:32:03.568033659Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8462a55f",
    "outputId": "77384fa5-e507-4544-ee84-f670063a9098"
   },
   "outputs": [],
   "source": [
    "original_results = normalize(results)\n",
    "original_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c0860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611483215Z",
     "start_time": "2023-11-29T22:32:03.568113897Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "621c0860",
    "outputId": "6a02fb5e-9ea1-49b4-e79e-8d64e22584f8"
   },
   "outputs": [],
   "source": [
    "vals = np.array(list(normalize(results).values()))\n",
    "#nqubits = datafile.shape[1]\n",
    "fidelity_uniform_sqrt = np.sum(np.sqrt(vals*(1/pow(2, nqubits))))\n",
    "print(\"Fidelity with a uniform distribution:\", fidelity_uniform_sqrt**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe36c8f",
   "metadata": {
    "id": "afe36c8f"
   },
   "source": [
    "## Create measurement dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e0130",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611566273Z",
     "start_time": "2023-11-29T22:32:03.568622501Z"
    },
    "id": "c21e0130"
   },
   "outputs": [],
   "source": [
    "class MeasurementDataset(Dataset):\n",
    "\n",
    "    def __init__(self, numpy_array:np.ndarray):\n",
    "        # dataloading\n",
    "        self.x = torch.from_numpy(numpy_array[:,:])\n",
    "        self.num_samples = numpy_array.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # dataset[0]\n",
    "        return self.x[index].float()\n",
    "\n",
    "    def __len__(self):\n",
    "        # len(dataset)\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48ea31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611722698Z",
     "start_time": "2023-11-29T22:32:03.568745997Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c48ea31",
    "outputId": "1062602b-b1e9-4d6f-a7ce-c33e85a3b257"
   },
   "outputs": [],
   "source": [
    "# Setup training and testing datasets\n",
    "\n",
    "want_datasetsize= 0.05  # can change to 0.2\n",
    "train_size = 0.75\n",
    "training_dataset = MeasurementDataset(outputfile[: int(want_datasetsize*train_size * n_samples)])\n",
    "valid_dataset = MeasurementDataset(outputfile[int(want_datasetsize*train_size * n_samples) : int(want_datasetsize * n_samples)])\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_dataset, batch_size=1, shuffle=True, num_workers=1\n",
    ")\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "\n",
    "dataloaders = [train_dataloader, valid_dataloader]\n",
    "dataloader_info = \"Size of training set: %d | Size of validation set: %d\"% (len(train_dataloader), len(valid_dataloader))\n",
    "print(dataloader_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf801c",
   "metadata": {
    "id": "ceaf801c"
   },
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f50641",
   "metadata": {
    "id": "a8f50641"
   },
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59752018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:03.611805425Z",
     "start_time": "2023-11-29T22:32:03.568806445Z"
    },
    "id": "59752018"
   },
   "outputs": [],
   "source": [
    "def create_qnn(num_inputs: int, num_qubits: int, qc_params: dict):\n",
    "    \"\"\"Creates the decoder circuit with ansatz\"\"\"\n",
    "\n",
    "    if num_inputs > num_qubits:\n",
    "        raise ValueError(\n",
    "            \"Number of inputs is greater than the number of qubits... Not suitable with current feature map\"\n",
    "        )\n",
    "\n",
    "    fm, entanglement_type, repititions = qc_params.values()\n",
    "\n",
    "    if fm == \"ZZ\":\n",
    "        feature_map = qiskit.circuit.library.ZZFeatureMap(num_inputs)\n",
    "    elif fm == \"Z\":\n",
    "        feature_map = qiskit.circuit.library.ZFeatureMap(num_inputs)\n",
    "    elif fm == 'P':\n",
    "        feature_map = qiskit.circuit.library.PauliFeatureMap(num_inputs, reps=1, paulis=['X', 'Y'],\n",
    "                                                             insert_barriers=True)\n",
    "    else:\n",
    "        raise ValueError(\"Wrong feature Map provided!\")\n",
    "\n",
    "    # local_entanglement = {}\n",
    "    ansatz = qiskit.circuit.library.TwoLocal(\n",
    "        num_qubits=num_qubits,\n",
    "        rotation_blocks=[\"ry\", \"rx\"],\n",
    "        entanglement_blocks=\"cx\",\n",
    "        skip_final_rotation_layer=False,\n",
    "        entanglement=entanglement_type,\n",
    "        reps=repititions,  # 1\n",
    "        insert_barriers=True,\n",
    "    )\n",
    "    qc = qiskit.QuantumCircuit(num_qubits)\n",
    "    qc.append(feature_map, range(0, num_inputs))\n",
    "    qc.h(range(num_inputs, num_qubits)) if num_inputs < num_qubits else None\n",
    "    qc.barrier()\n",
    "    qc.append(ansatz, range(num_qubits))\n",
    "    qnn = SamplerQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "        sparse=False,\n",
    "    )\n",
    "    return qnn, qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675dddfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.098494517Z",
     "start_time": "2023-11-29T22:32:03.568863304Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "675dddfa",
    "outputId": "63f7ede9-1d0f-47ba-b23c-dddb7cc4720f"
   },
   "outputs": [],
   "source": [
    "qnn_sample, qnn_qc_sample = create_qnn(num_inputs=4, num_qubits=4, qc_params= {'fm':'Z',\n",
    "                                                                 'entanglement_type':'linear',\n",
    "                                                                  'repititions':2})\n",
    "tc_qc_sample = qiskit.transpile(qnn_qc_sample, basis_gates=['h','rx','ry','cx'])\n",
    "\n",
    "tc_qc_sample.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27681d2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.101891382Z",
     "start_time": "2023-11-29T22:32:04.098608383Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27681d2a",
    "outputId": "ddada183-0a35-4be0-e1c0-6c810b8b016e"
   },
   "outputs": [],
   "source": [
    "print(\"Original circuit number of operations: \", circ_simple.count_ops())\n",
    "print(\"Ansatz circuit number of operations: \", tc_qc_sample.count_ops())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee794dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.107932146Z",
     "start_time": "2023-11-29T22:32:04.102626949Z"
    },
    "id": "1ee794dc"
   },
   "outputs": [],
   "source": [
    "class QVAE_qcompile(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, qnn, latent_dim:int):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(qnn.circuit.num_qubits, 8),\n",
    "            torch.nn.LeakyReLU(0.01),\n",
    "            torch.nn.Linear(8, 7),\n",
    "            torch.nn.LeakyReLU(0.01))\n",
    "\n",
    "        self.z_mean = torch.nn.Linear(7,latent_dim)\n",
    "        self.z_log_var = torch.nn.Linear(7,latent_dim)\n",
    "\n",
    "        # self.preprocessor = torch.nn.Sequential(\n",
    "        #     torch.nn.Linear(latent_dim, qnn.circuit.num_qubits),\n",
    "        #     torch.nn.LeakyReLU(0.01))\n",
    "\n",
    "        self.preprocessor = torch.nn.Linear(latent_dim, qnn.circuit.num_qubits)\n",
    "        torch.nn.init.normal_(self.preprocessor.weight, mean=0, std=0.01)\n",
    "        torch.nn.init.constant_(self.preprocessor.bias, val=0)\n",
    "\n",
    "        self.decoder = TorchConnector(qnn)\n",
    "\n",
    "    def encoding_fn(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        return encoded\n",
    "\n",
    "    def decoding_fn(self, x):\n",
    "        x = self.preprocessor(x)\n",
    "        decoded = self.decoder(x)\n",
    "        return decoded\n",
    "\n",
    "    def reparameterize(self, z_mu, z_log_var):\n",
    "        eps = torch.randn(z_mu.size(0), z_mu.size(1))\n",
    "        z = z_mu + eps * torch.exp(z_log_var/2.)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        z_mean, z_log_var = self.z_mean(x), self.z_log_var(x)\n",
    "        encoded = self.reparameterize(z_mean, z_log_var)\n",
    "        preprocessed = self.preprocessor(encoded)\n",
    "        decoded = self.decoder(preprocessed)\n",
    "        return encoded, z_mean, z_log_var, decoded #preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39d25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.115418427Z",
     "start_time": "2023-11-29T22:32:04.112250864Z"
    },
    "id": "6f39d25b"
   },
   "outputs": [],
   "source": [
    "class Decoder_distribution():\n",
    "    \"\"\"Get distribution by sampling latent space of classial or quantum VAE\"\"\"\n",
    "\n",
    "    def __init__(self, model, original_results:dict, nn_type:str, nsamples:int):\n",
    "        self.model = model\n",
    "        self.original_results = normalize(original_results) # set sum frequency = 1\n",
    "        self.nsamples = nsamples\n",
    "        self.nn_type = nn_type\n",
    "\n",
    "    def get_outputstate_from_latentspace_CVAE(self) -> str:\n",
    "        \"\"\"For classical VAE: Sample from normal(0,1) from latent space and provide a single\n",
    "        output bitstring\"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(self.model.z_mean.out_features) # inputs go through preprocessor\n",
    "            output = self.model.decoding_fn(sample)\n",
    "            p = torch.rand(output.shape) #np.random.rand(1)[0]\n",
    "            state = torch.where(output>p, 1, 0)\n",
    "            bitstring = np.apply_along_axis(\"\".join, 0, state.numpy().astype(int).astype(str))\n",
    "        return bitstring\n",
    "\n",
    "    def get_ouputdict_from_bitstrings(self, output_dict:dict, bitstring:str) -> dict:\n",
    "        \"\"\"If Bitstring is present in output dict then increase count by 1,\n",
    "        otherwise create new key\"\"\"\n",
    "        if bitstring.item() in output_dict.keys():\n",
    "            output_dict[bitstring.item()] += 1\n",
    "        else:\n",
    "            output_dict[bitstring.item()] = 1\n",
    "            #print(bitstring.item())\n",
    "        return output_dict\n",
    "\n",
    "    def get_decoder_dist_QVAE(self):\n",
    "        \"\"\"For QVAE: Sample from latent space and return marginalised distribution\"\"\"\n",
    "        nqubits = self.model.encoder[0].in_features\n",
    "        outputs = np.zeros(( self.nsamples, pow(2, nqubits) ))\n",
    "        with torch.no_grad():\n",
    "            for idx, _ in enumerate(outputs):\n",
    "                sample = torch.randn(self.model.z_mean.out_features)\n",
    "                outputs[idx, :] = self.model.decoding_fn(sample)\n",
    "        outputs = outputs.mean(axis=0)\n",
    "        bitstring_basis = [(\"{0:0%db}\"%nqubits).format(i) for i in range(pow(2, nqubits))]\n",
    "\n",
    "        return dict(zip(bitstring_basis, outputs))\n",
    "\n",
    "    def get_fidelity(self, model_output_dict:dict) -> float:\n",
    "        \"\"\"Get Bhattacharya co-efficienct of two discrete distributions.\n",
    "        The two distributions are normalized (sum of frequencies set to 1) before computation\"\"\"\n",
    "        fidelity_sqrt = 0\n",
    "        for key in self.original_results.keys():\n",
    "            if key in model_output_dict.keys():\n",
    "                fidelity_sqrt += np.sqrt(self.original_results[key]*model_output_dict[key])\n",
    "        return fidelity_sqrt**2\n",
    "\n",
    "    def get_no_wrong_samples(self, model_output_dict:dict) -> float:\n",
    "        \"\"\"Get the number of wrong samples from the learnt distribution and the mass on right samples\n",
    "        Wrong sample: bitstring that is not in original_results and has positive probability in learnt distribution\"\"\"\n",
    "        wrong_samples = 0\n",
    "        for basis_state in model_output_dict.keys():\n",
    "            if (basis_state not in self.original_results) & (model_output_dict[basis_state] != 0):\n",
    "                wrong_samples += 1\n",
    "        return wrong_samples\n",
    "\n",
    "    def get_mass_rightsamples(self, model_output_dict:dict) -> float:\n",
    "        \"\"\"Get mass of right samples\n",
    "        Sum of masses in learnt distribution that is on the basis seen in the original dist\"\"\"\n",
    "        mass_right_samples = 0\n",
    "        for basis_state in self.original_results:\n",
    "            if basis_state in model_output_dict.keys():\n",
    "                mass_right_samples += self.original_results[basis_state]\n",
    "        return mass_right_samples\n",
    "\n",
    "    def get_decoder_distribution(self):\n",
    "        \"\"\"Get distribution from decoder\"\"\"\n",
    "        #output_states = np.zeros((self.nsamples, self.model.decoder[0].in_features))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if self.nn_type == \"classical\":\n",
    "                output_dict = {}\n",
    "                for i in range(self.nsamples):\n",
    "                    bitstring = self.get_outputstate_from_latentspace_CVAE()\n",
    "                    output_dict = self.get_ouputdict_from_bitstrings(output_dict, bitstring)\n",
    "\n",
    "            elif self.nn_type == \"quantum-classical\":\n",
    "                output_dict = self.get_decoder_dist_QVAE()\n",
    "\n",
    "        output_dict = normalize(output_dict)\n",
    "        no_wrong_samples = self.get_no_wrong_samples(output_dict)\n",
    "        mass_right_samples = self.get_mass_rightsamples(output_dict)\n",
    "        fidelity = self.get_fidelity(output_dict)\n",
    "        return output_dict, no_wrong_samples, mass_right_samples, fidelity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc38b2",
   "metadata": {
    "id": "cccc38b2"
   },
   "source": [
    "### Setup training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36490cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.180750253Z",
     "start_time": "2023-11-29T22:32:04.115779396Z"
    },
    "id": "36490cb3"
   },
   "outputs": [],
   "source": [
    "# Set simulation parameters\n",
    "\n",
    "nqubits=4\n",
    "featuremap = \"P\"\n",
    "patience = 7\n",
    "minibatchsize=32\n",
    "beta = 1\n",
    "latentsize=4\n",
    "annealing_schedule = 'fixed' # stepfn, linear, fixed, zero, stepfn_linear\n",
    "nn_type= \"quantum-classical\" # quantum-classical, classical\n",
    "\n",
    "encoder_lr = 0.004; decoder_lr = 0.009\n",
    "learning_rates = [encoder_lr, decoder_lr]\n",
    "\n",
    "num_epochs = 50\n",
    "# root_dir = os.path.join(project_dir, \"log-files/Quantumcircuit-states\")\n",
    "# print(true_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe5ccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.180968756Z",
     "start_time": "2023-11-29T22:32:04.120581819Z"
    },
    "id": "12fe5ccf"
   },
   "outputs": [],
   "source": [
    "model = QVAE_qcompile(qnn_sample, latent_dim=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a658d15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.293074167Z",
     "start_time": "2023-11-29T22:32:04.164102793Z"
    },
    "id": "5a658d15"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    [\n",
    "        {\"params\":model.encoder.parameters(), \"lr\":encoder_lr},\n",
    "     {\"params\":model.z_mean.parameters(), \"lr\":encoder_lr},\n",
    "    {\"params\":model.z_log_var.parameters(), \"lr\":encoder_lr},\n",
    "    {\"params\":model.preprocessor.parameters(), \"lr\":encoder_lr},\n",
    "    {\"params\":model.decoder.parameters(), \"lr\":decoder_lr}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c8483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.340347267Z",
     "start_time": "2023-11-29T22:32:04.295132534Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a35c8483",
    "outputId": "0daf2dad-7e9c-4d67-bd0a-f29c6c7c290b"
   },
   "outputs": [],
   "source": [
    "# Print number of trainable parameters\n",
    "encoder_trainable_params = sum(\n",
    "    p.numel() for p in model.encoder.parameters() if p.requires_grad\n",
    ")\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "trainparams_info = \"No of trainable parameters: \\n (Model:%d) | (Encoder:%d) | (Decoder:%d)\"%(trainable_params,\n",
    "                                                                                              encoder_trainable_params,\n",
    "                                                                                              qnn_sample.num_weights)\n",
    "epoch_batch_info = \"Total number of epochs: %d | Total number of batches: %d\"%(num_epochs,\n",
    "                                                                               math.ceil(len(dataloaders[0])/minibatchsize))\n",
    "\n",
    "print(trainparams_info,'\\n',epoch_batch_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eecc47f",
   "metadata": {
    "id": "3eecc47f"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26500f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.340474433Z",
     "start_time": "2023-11-29T22:32:04.340129724Z"
    },
    "id": "5d26500f"
   },
   "outputs": [],
   "source": [
    "logdict = {\"train_combined_loss_per_minibatch\": [],\n",
    "            \"train_reconstruction_loss_per_minibatch\": [],\n",
    "            \"train_kl_loss_per_minibatch\": [],\n",
    "            \"valid_reconstruction_loss\": []}\n",
    "\n",
    "all_bitstrings = [(\"{0:0%db}\"%nqubits).format(i) for i in range(pow(2, nqubits))]\n",
    "output_qubits = 4\n",
    "\n",
    "decoder_params_list = []\n",
    "no_wrong_samples,right_samples_mass,output_dict_list, fidelity_list = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e6b56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T22:32:04.341722295Z",
     "start_time": "2023-11-29T22:32:04.340206721Z"
    },
    "id": "c7e6b56d"
   },
   "outputs": [],
   "source": [
    "def validation_loss(model, valid_dataloader, all_bitstrings):\n",
    "\n",
    "    output_qubits = model.encoder[0].in_features\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(valid_dataloader):\n",
    "            encoded, z_mean, z_log_var, decoded = model(data)\n",
    "            input_bitstring = np.apply_along_axis(\"\".join, 1, data.detach().numpy().astype(int).astype(str))\n",
    "            meas_dict = dict(zip(all_bitstrings,(decoded.squeeze() + pow(2, -18))/ (1 + pow(2, -18) * pow(2, output_qubits)),))\n",
    "            likelihood_losses = -torch.log(meas_dict[input_bitstring[0]])\n",
    "            total_val_loss += likelihood_losses\n",
    "\n",
    "        return total_val_loss / len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a217ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:33.523385881Z",
     "start_time": "2023-11-29T22:32:04.340319428Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a217ad7",
    "outputId": "55e6ee1c-8086-41a4-c3c4-e5d5893a2f8d"
   },
   "outputs": [],
   "source": [
    "loss_list = []\n",
    "\n",
    "# Early stopping\n",
    "last_loss = 20\n",
    "init_mass_rightsamples = 0\n",
    "trigger_times = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = []\n",
    "    epoch_kl_loss = []\n",
    "    epoch_mse_loss = []\n",
    "\n",
    "    kl_term_weight = beta\n",
    "    minibatchsize_no = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_dataloader):\n",
    "\n",
    "        # Forward pass\n",
    "        encoded, z_mean, z_log_var, decoded = model(data)\n",
    "        input_bitstring = np.apply_along_axis(\"\".join, 1, data.numpy().astype(int).astype(str))\n",
    "        measurement_dict = dict(zip(all_bitstrings,(decoded.squeeze() + pow(2, -18))\n",
    "                            / (1 + pow(2, -18) * pow(2, output_qubits)),))\n",
    "        likelihood_losses = -torch.log(measurement_dict[input_bitstring[0]])\n",
    "\n",
    "        # Normalize loss for batch accumulation\n",
    "        mean_ll = likelihood_losses / minibatchsize\n",
    "        kl_loss = -0.5 * torch.sum(\n",
    "            1 + z_log_var - z_mean ** 2 - torch.exp(z_log_var)\n",
    "        )\n",
    "        kl_loss = (kl_term_weight * kl_loss) / minibatchsize\n",
    "        loss = mean_ll + kl_loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # weights update\n",
    "        if ((batch_idx + 1) % minibatchsize == 0) or (batch_idx + 1 == len(train_dataloader)):\n",
    "            minibatchsize_no += 1\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)  # reset gradients to zero\n",
    "\n",
    "            # Store losses\n",
    "            total_loss.append(loss.item())\n",
    "            epoch_mse_loss.append(mean_ll.item())\n",
    "            epoch_kl_loss.append(kl_loss.item())\n",
    "\n",
    "            print(\n",
    "                \"(%d|%d , %d|%d) Total loss: %.5f | Likelihood loss: %.5f | KL loss : %.5f \"\n",
    "                % (epoch + 1,num_epochs,minibatchsize_no,\n",
    "                    math.ceil(len(train_dataloader) /minibatchsize),\n",
    "                    loss.item(),mean_ll.item(),kl_loss.item(),))\n",
    "\n",
    "            # LOGGING\n",
    "            logdict[\"train_combined_loss_per_minibatch\"].append(loss.item())\n",
    "            logdict[\"train_reconstruction_loss_per_minibatch\"].append(mean_ll.item())\n",
    "            logdict[\"train_kl_loss_per_minibatch\"].append(kl_loss.item())\n",
    "\n",
    "    end_time = time.time()\n",
    "    valid_loss = validation_loss(model, valid_dataloader, all_bitstrings)\n",
    "    logdict[\"valid_reconstruction_loss\"].append(valid_loss)\n",
    "\n",
    "\n",
    "    decoder_params = model.decoder.weight.detach().numpy().copy()\n",
    "    encoder_params = [param.detach().numpy().tolist() for param in model.encoder.parameters()]\n",
    "    decoder_params_list.append(decoder_params)\n",
    "\n",
    "    output_dist = Decoder_distribution(model, original_results, nn_type='quantum-classical', nsamples=5000)\n",
    "    (output_dict,n_wrong_samples,mass_right_samples,fidelity) = output_dist.get_decoder_distribution()\n",
    "\n",
    "    no_wrong_samples.append(n_wrong_samples)\n",
    "    right_samples_mass.append(mass_right_samples)\n",
    "    output_dict_list.append(output_dict)\n",
    "    fidelity_list.append(fidelity)\n",
    "    print(\"Fidelity:\", fidelity)\n",
    "\n",
    "    # Store loss for epoch\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "\n",
    "    print(\"Time taken %4fs\" % (end_time - start_time))\n",
    "    print(\"Epoch: %02d/%02d | Beta %.3f | Avg Train Loss: %.4f | Valid Loss: %.4f | Wrong states: %d | Mass on right states %.4f\\n\"\n",
    "        %(epoch + 1,num_epochs,kl_term_weight,loss_list[-1],\n",
    "            valid_loss,n_wrong_samples,mass_right_samples,))\n",
    "\n",
    "    if valid_loss > last_loss:  # mass_right_samples < init_mass_rightsamples:\n",
    "        trigger_times += 1\n",
    "        #trigger_vals.append(trigger_times)\n",
    "        print(f\"Trigger Times: {trigger_times} \\n\")\n",
    "\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping! Closing training. Now can start to test process.\")\n",
    "            break\n",
    "\n",
    "    elif valid_loss <= last_loss:\n",
    "        # mass_right_samples >= init_mass_rightsamples:\n",
    "        print(\"Trigger times: 0\\n\")\n",
    "        trigger_times = 0\n",
    "        last_loss = valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866feebd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:33.800611551Z",
     "start_time": "2023-11-29T23:07:33.468137882Z"
    },
    "id": "866feebd"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(16,4))\n",
    "\n",
    "titles=['Total loss', 'Reconstruction loss', 'KL loss', 'Validation loss']\n",
    "for idx, (key, value) in enumerate(logdict.items()):\n",
    "    ax[idx].plot(value)\n",
    "    ax[idx].set(title=titles[idx], xlabel=\"No epochs\")\n",
    "\n",
    "ax[4].plot(fidelity_list)\n",
    "ax[4].set(title=\"fidelity\", xlabel=\"No epochs\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a887a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:37.908004884Z",
     "start_time": "2023-11-29T23:07:33.801942129Z"
    },
    "id": "8a887a41"
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "random_samples = torch.randn(n_samples, 4)\n",
    "output_dist = np.zeros((n_samples, pow(2,4)))\n",
    "\n",
    "for idx, sample in enumerate(random_samples):\n",
    "    with torch.no_grad():\n",
    "        processed_sample = model.preprocessor(sample)\n",
    "        output_dist[idx, :] = model.decoder(processed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166d15d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:37.911832294Z",
     "start_time": "2023-11-29T23:07:37.908560137Z"
    },
    "id": "166d15d0"
   },
   "outputs": [],
   "source": [
    "original_results\n",
    "\n",
    "orig_dist_sorted = []\n",
    "for bitstring in all_bitstrings:\n",
    "    orig_dist_sorted.append(original_results[bitstring])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13666ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:37.938938113Z",
     "start_time": "2023-11-29T23:07:37.911133916Z"
    },
    "id": "13666ff7"
   },
   "outputs": [],
   "source": [
    "final_fidelity = 0\n",
    "for idx in range(16):\n",
    "    final_fidelity += np.sqrt(orig_dist_sorted[idx]*output_dist.mean(axis=0)[idx])\n",
    "final_fidelity = final_fidelity**2\n",
    "\n",
    "print(\"Learnt distribution fidelity:\", final_fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c77d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:38.060296387Z",
     "start_time": "2023-11-29T23:07:37.931736059Z"
    },
    "id": "165c77d1"
   },
   "outputs": [],
   "source": [
    "plt.bar(np.arange(16)-0.2, orig_dist_sorted, width=0.25, label=\"Original distribution\")\n",
    "plt.bar(np.arange(16)+0.2, output_dist.mean(axis=0), width=0.25, label=\"Learnt distribution\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks(np.arange(16), all_bitstrings, rotation=45)\n",
    "plt.ylabel(\"Quasi-probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d93daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T23:07:38.158460871Z",
     "start_time": "2023-11-29T23:07:38.060060044Z"
    },
    "id": "69d93daf"
   },
   "outputs": [],
   "source": [
    "# The parameters of the ansatz the yield the same measurement distribution are:\n",
    "list(model.decoder.parameters())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b440201f410f53d",
   "metadata": {
    "collapsed": false,
    "id": "b440201f410f53d",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# References\n",
    "1. A wikipedia page on Autoencoder: https://en.wikipedia.org/wiki/Autoencoder\n",
    "\n",
    "2. Romero, Jonathan, Jonathan P. Olson, and Alan Aspuru-Guzik. \"Quantum autoencoders for efficient compression of quantum data.\" Quantum Science and Technology 2.4 (2017): 045001.\n",
    "\n",
    "3. Swap Test Algorithm: https://en.wikipedia.org/wiki/Swap_test\n",
    "4. https://doi.org/10.48550/arXiv.2305.01592"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

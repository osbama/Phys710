{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training parameterized quantum circuits\n",
    "\n",
    "Like classical models, we can train parameterized quantum circuit models to perform data-driven tasks. The task of learning an arbitrary function from data is mathematically expressed as the minimization of a cost function (To compare different parameters, we need to score them according to some criteria. We call the function that scores our parameters the ‘cost’ or ‘loss’ function, as bad results are more costly.) or loss function $f(\\vec\\theta)$, also known as the objective function, with respect to the parameter vector $\\vec\\theta$. Generally, when training a parameterized quantum circuit model, the function we are trying to minimise is the expectation value $ \\langle \\Psi(\\vec\\theta) | \\hat{H}| \\Psi(\\vec\\theta) \\rangle $\n",
    "\n",
    "![](./training.png)\n",
    "\n",
    "There are many different types of algorithms that we can use to optimise the parameters of a variational circuit, $\\mathbf{U_\\theta}$, (gradient-based, evolutionary, and gradient-free methods). In this course, we will be discussing gradient-based methods.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "544df0c5017bba8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
